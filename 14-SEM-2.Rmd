```{r, echo=FALSE}
set.seed(20221010)
```

# Latent variable models (SEM 2) {#ch-SEM-latent-variable-models}

The previous chapter concerned a multivariate model to describe relations between *observed* variables. In this Chapter, we will extend this idea by adding **latent variables**. Latent variables are variables which can not be directly observed, but they can be measured or inferred via their relation with observed variables. A classic example is a personality trait such as extraversion. People's tendency to be outwards facing is not directly observable. However, there are many indicators (e.g., someone actively seeking out busy social situations, liking to be the centre of attention, etc.) which together may allow one to determine the relative extraversion of person. Most commonly, extraversion is measured via questionnaires such as the .... Factor analysis is applied to 

## Factor analysis

```{r}
library(psychTools)
data(bfi)
```

### Exploratory factor analysis and principal components analysis

```{r}
bfi_cor <- cor(bfi[,-c(26:28)], use="pairwise.complete.obs")
bfi_pca <- prcomp(bfi_cor)
summary(bfi_pca)

bfi_pca <- psych::principal(bfi_cor)
summary(bfi_pca)
```

Although not really a part of Structural Equation Models, it is instructive to also briefly discuss **data reduction** techniques such as principal components analysis and exploratory factor analysis. These methods aim to describe a $P \times P$ covariance (or correlation) matrix by means of relatively small set of variables. Essentially, both methods rely on saturated models which can replicate the sample covariance matrix perfectly.

The differences between principal component analysis and exploratory factor analysis are somewhat subtle. **Principal components analysis** (PCA) can be seen as applying a **formative model**, where observed variables "cause" the latent variables (called a principal components in this context). **Principal components** (which we will denote as $\text{PC}_j$) are simply linear functions of the variables:
$$\begin{aligned}
\text{PC}_1 &= w_{1,1} \times X_{1} + w_{1,2} \times X_{2} + w_{1,m} \times \ldots X_{m} \\
\text{PC}_2 &= w_{2,1} \times X_{1} + w_{2,2} \times X_{2} + w_{2,m} \times \ldots X_{m} \\
& \vdots \\
\text{PC}_m &= w_{m,1} \times X_{1} + w_{m,2} \times X_{2} + w_{m,m} \times \ldots X_{m}
\end{aligned}$$
Note that the principal components $\text{PC}_j$ have no error terms. They don't need to be estimated, but rather are *computed* from the variables $X_j$. Also note that we use a total of $m$ principal components to model a total of $m$ variables. 

By contrast, **exploratory factor analysis** (PCA) concerns a **reflective model**, where the latent variable "causes" the observed variables. A EFA model can be written as:
$$\begin{aligned}
Y_1 &= \lambda_{1,1} \times F_{1} + \lambda_{1,2} \times F_{2} + \ldots + \lambda_{1,q} \times  F_{q} + \epsilon_{1} && \epsilon_{1} \sim \mathbf{Normal}(0, \sigma_{\epsilon_1}) \\
Y_2 &= \lambda_{2,1} \times F_{1} + \lambda_{2,2} \times F_{2} + \ldots + \lambda_{2,q} \times F_{q} + \epsilon_{2} && \epsilon_{2} \sim \mathbf{Normal}(0, \sigma_{\epsilon_1}) \\
& \vdots \\
Y_m &= \lambda_{m,1} \times F_{1} + \lambda_{m,2} \times F_{2} + \ldots + \lambda_{m,q} \times F_{q} + \epsilon_{m} && \epsilon_{m} \sim \mathbf{Normal}(0, \sigma_{\epsilon_m}) 
\end{aligned}
(\#eq:sem-2-efa-definition)$$
with the number of factors $q < m$. In a EFA, the observed variables $Y_j$ are considered conditionally independent, given the factors $F_k$. This is evident from the (independently distributed) error terms $\epsilon_j$. 

```{r}
library(lavaan)
# mod_spec <- '
# pc <- 1*E1 + 1*E2 + 1*E3 + 1*E4 + 1*E5
# E1 ~ 1
# E2 ~ 1
# E3 ~ 1
# E4 ~ 1
# E5 ~ 1
# #E1 ~~ E2 + E3 + E4 + E5
# #E2 ~~ E3 + E4 + E5
# #E3 ~~ E4 + E5
# #E4 ~~ E5
# '
# pca_lmod <- lavaan::sem(mod_spec, data=bfi)
# 
# ### PCA vs EFA
# 
# mod_spec <- '
# efa("block1")f1 =~ E1 + E2 + E3 + E4 + E5
# efa("block2")f2 =~ E1 + E2 + E3 + E4 + E5
# #E1 ~ 1
# #E2 ~ 1
# #E3 ~ 1
# #E4 ~ 1
# #E5 ~ 1
# #E1 ~~ E2 + E3 + E4 + E5
# #E2 ~~ E3 + E4 + E5
# #E3 ~~ E4 + E5
# #E4 ~~ E5
# '
# pca_lmod <- lavaan::sem(mod_spec, data=bfi)

### PCA vs EFA
```




```{r}
### Venn diagram for PCA/EFA
```


#### Determining the number of factors

#### Factor rotation

There are two main types of factor rotation: in **orthogonal rotation**, the factors are constrained to be independent of each other (i.e. there is no residual covariation between the factors). In **oblique rotation**, factors are allowed to have residual covariation. 

### Confirmatory factor analysis

Like EFA, confirmatory factor analysis (CFA) concerns a reflective model, where a factor causes the item values. But unlike PCA and EFA, CFA does not generally employ a saturated model. Items generally have paths from only a small set of the total number of factors. Th

```{r}
### bfi CFA
mod_spec <- '
Fa =~ A1 + A2 + A3 + A4 + A5 
Fc =~ C1 + C2 + C3 + C4 + C5
Fe =~ E1 + E2 + E3 + E4 + E5
Fn =~ N1 + N2 + N3 + N4 + N5
Fo =~ O1 + O2 + O3 + O4 + O5
'

bfi_cfa <- lavaan::cfa(mod_spec, data=bfi)
```

## Modification indices

Modification indices 

## General SEMs

```{r}
library(sdamr)
data(speeddate)
speed_cor <- cor(speeddate[,c("other_attr", "other_sinc", "other_intel", "other_fun", "other_amb")], use="pairwise.complete.obs")
#psych::fa(speed_cor, nfactors = 5, n.obs=nrow(speeddate), rotate="none")

psych::fa(speeddate[,c("other_attr", "other_sinc", "other_intel", "other_fun", "other_amb")], nfactors = 4, rotate="none")
```

### Measurement model

The relations between a latent variable and the observed variables are called a **measurement model**.

```{r}

```

### Structural (path) model

### Indentification

Hayward case

## Conclusion



<!-- use PoliticalDemocracy data from lavaan. Code from https://www.lavaan.ugent.be/tutorial/sem.html -->

<!-- ## Multi-group SEM -->

## In practice