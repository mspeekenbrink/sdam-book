# A model with a mean (one sample t-test)

In this chapter, we will start our journey into the General Linear Model with the most basic example within the GLM: a model concerning a single Normal distribution, where we are interested in statements about the mean of that distribution. We will look at the Normal distribution in detail, and cover estimation of its parameters, before focusing on testing hypotheses about the mean. We end the chapter with a look ahead towards the other chapters, by providing a brief overview of the General Linear Model.

## Numeric judgement and anchoring

In 1906, Sir Francis Galton attended The West of England Fat Stock and Poultry Exhibition in Plymouth. One of the attractions at the fair was a contest to guess the weight of a "dressed" ox on display. The nearest guess to the actual weight of the ox would win a prize, and a total of 800 attendees participated for a small fee. Not only was Francis Galton a eugenicist^[He founded the Galton Laboratory of National Eugenics at UCL.] -- and rightly condemned for this in more modern times -- he was also a statistician, and bought the used tickets off the stall holder. Back home he analysed the 787 usable tickets and later published his findings [@galton1907vox]. What surprised Galton was that while the individual guesses were often far from the true weight of the ox, the average guess of the group as a whole was highly accurate. Such findings are now often referred to as the "Wisdom of the crowds".

Although the wisdom of the crowds has been demonstrated in various domains, from decades of research, we also know that human judgement is subject to a long list of biases. One such bias is called "anchoring", and it pertains to the influence of prior exposure to a more or less arbitrary numerical value on the subsequent numerical judgement. For instance, if I ask you "to estimate the height of"How tall do you think Mount Everest is?", but first state that Mount Everest is taller than 2000 feet, you are likely to give a smaller number than if I first state that Mount Everest is shorter than 45,500 feet. 

In this example, we will focus on data obtained from a large scale replication study, covering the above described anchoring manipulation, as well as many other experiments [@klein2014investigating]. This "Many Labs" study contained data collected by a large number of labs from different countries, and here we will use data collected by Konrad Bocian and Natalia Frankowska from the University of Social Sciences
and Humanities Campus in Sopot, Poland. In particular, we will focus on the judged height of Mount Everest (in meters) after a low anchor. From the wisdom of the crowds idea, we might expect the average judgement to be identical (or at least very close) to the true height of Mount Everest, which is 8848 meters above sea level. On the other hand, if the low anchor biased the judgements, we might expect the average judgement to deviate from the true height.

```{r load-anchoring, echo = FALSE}
library(sdamr)
library(ggplot2)
data(anchoring)
dat <- subset(anchoring,referrer %in% c("swps","swpson") & anchor == "low")
```

### Exploring the data

Before diving into statistical modelling, as discussed, it is always good to explore the data. A graphical overview in the form of a histogram and raincloud plot is given in Figure \@ref(fig:anchoring-eda-plots). The minimum was judged height was `r min(dat$everest_meters)` meters (so quite close to the anchor), and the maximum was `r pretNum(max(dat$everest_meters))` meters. The median judgement was `r median(dat$everest_meters)` and the mean `r mean(dat$everest_meters)`. The sample variance of the judgements was `r pretNum((length(dat$everest_meters) -1)*var(dat$everest_meters)/length(dat$everest_meters))` and the sample standard deviation `r sqrt((length(dat$everest_meters) -1)*var(dat$everest_meters)/length(dat$everest_meters))`. 

```{r anchoring-eda-plots, echo=FALSE, fig.cap="Histogram and boxplot of participants' judgments", fig.show="hold", out.width="48%", fig.width=3, fig.height=3}
ggplot(dat,aes(x=everest_meters)) + geom_histogram(binwidth=500) + xlab("Height of Mount Everest in meters")

# ggplot(dat,aes(y=everest_meters, x="")) + geom_violin() + geom_boxplot(width=.1) + ylab("Height of Mount Everest in meters") + xlab("") + stat_summary(fun=mean, geom="point", shape=16, size=2)
plot_raincloud(dat,y = everest_meters, point_size=1) + ylab("Height of Mount Everest in meters")
```

Looking at Figure \@ref(fig:anchoring-eda-plots), you can see a peak in the distribution around the true height of Mount Everest (8848 meters), but the judgements are also quite varying, with quite a large number of judgements substantially below the actual height. This may be due to some people knowing the correct answer, whilst others don't and have to guess. Those guessing would likely be more influenced by the low anchor. The question is whether, on average, the group's judgements are equal to the actual height of Mount Everest.

## A statistical model of judgements

Clearly, not everyone gave a correct answer, and there is substantial variation in people's judgements. The goal of a statistical model is to account for this variation. In this chapter, we will consider one of the simplest statistical models for metric data such as the judgements, namely the Normal distribution. In this model, we will assume that the variation in judgements is entirely random. We may also assume that, on average, the judgements are equal to the actual height of Mount Everest, but some people will overestimate, and some people underestimate the height in their judgements. Moreover, we might assume that the probability of an underestimation is equal to the probability of an overestimation, and that very large over- or underestimations are less likely than smaller over- or underestimations. The Normal distribution encapsulates such assumptions.

### The Normal distribution

The __Normal distribution__ is the well-known bell-shaped curve depicted in Figure \@ref(fig:normal-density-plot).

```{r normal-density-plot, fig.cap="The Normal density function for $\\mu = 0$ and $\\sigma = 1$", fig.height=4,out.width="80%"}
ggplot() + stat_function(fun=function(x) dnorm(x,mean=0,sd=1)) + xlim(-4,4) + ylab("f(y)") + xlab("y")
```

The curve is given by the following function:

\begin{equation}
p(y) = \frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(y-\mu)^2}{2\sigma^2}}
(\#eq:normal-density-function)
\end{equation}

If that looks complicated, don't worry. First, let me point out that $\pi$ refers to the mathematical constant pi, i.e. $\pi= 3.141593\ldots$, and $e$ refers to the mathematical constant also known as Euler's number, i.e. $e =  2.718282\ldots$. They are known constants and not parameters. The Normal distribution does have two parameters: $\mu$ ("mu"), the mean, and $\sigma$ ("sigma"), also called the standard deviation. Confusingly, the formula above is not actually the formula for the Normal probability distribution. Rather, it is the formula of the Normal __density function__. The Normal distribution applies to continuous variables. Technically, you can't assign a probability to a particular value of a continuous variable, you can only assign probabilities to ranges of values. This is because a continuous variable has an infinite number of values (even if we restrict ourselves to a range). If we gave each unique value a probability of anything larger than 0, the total probability would not be 1, but infinite. If you add up an infinite amount of values, no matter how tiny they are, at some point you would reach a sum of 1, and then you'd have to keep on adding more. No matter how large the sum becomes, you would have to keep on going. Adding up an infinite number of values is not light work...

While we can't define probability of any particular value, the probability that an observation is within a particular range is well-defined. So, rather than asking "What is the probability that the height is exactly 8567.46384634748763...?", we can ask "What is the probability that the height is between 8567 and 8568?", or "What is the probability that the height is between 8567.575 and 8567.576?". These probabilities are defined by the "area under the curve" within that range. Using calculus, they can be computed as:

$$P(a \leq Y \leq b) = \int_a^b \frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{(y-\mu)^2}{2\sigma^2}} d y$$

If you are unfamiliar with calculus and have never seen an integration sign ($\int$), don't worry, you don't have to solve equations like this, and there won't be many more like this. You can just see it as a mathematical way of referring to the area under the curve between point $a$ and $b$. A proper probability density function respects the rule of total probability. The Normal distribution is defined over all real numbers (i.e. all possible numbers between minus infinity and infinity). Thus, the rule of total probability rquires that $P(-\infty \leq Y \leq \infty) = 1$, and this is true for the Normal distribution. Figure \@ref(fig:normal-distribution-plot) shows the probability of three ranges, each symmetrical around the mean. The probability of a value falling in the range between $\mu - 3 \times \sigma$ and $\mu + 3 \times \sigma$ is very close to 1. Hence, values more than three standard deviations from the mean are extremely unlikely.

```{r normal-distribution-plot, fig.cap="Normal distribution and the probability of a value falling in one of three overlapping ranges. Note that the ranges are overlapping, so that the range between $\\mu - 3 \\sigma$ and $\\mu + 3 \\sigma$ also covers the range between $\\mu - 2 \\sigma$ and $\\mu + 2 \\sigma$, but that this isn't shown in the colours.",fig.height=3}
library(scales)
library(dplyr)
library(tidyr)
#levels <- c(bquote("mu %+-% sigma %~~% .683"),bquote("mu %+-% 2 %*% sigma %~~% .954"),bquote("mu %+-% 3 %*% sigma %~~% .997"))[3:1]
levels <- c(bquote(mu %+-% sigma %~~% .683),bquote(mu %+-% 2 %*% sigma %~~% .954),bquote(mu %+-% 3 %*% sigma %~~% .997))[3:1]
rbind(data.frame(interval=1,x=c(-3,seq(-3,3,length=100),1),y=c(0,dnorm(seq(-3,3,length=100)),0)),
      data.frame(interval=2,x=c(-2,seq(-2,2,length=100),2),y=c(0,dnorm(seq(-2,2,length=100)),0)),
      data.frame(interval=3,x=c(-1,seq(-1,1,length=100),1),y=c(0,dnorm(seq(-1,1,length=100)),0))) %>%
  ggplot(aes(x=x,y=y,fill=factor(interval,labels=levels))) + stat_function(aes(fill=NULL),fun=function(x) dnorm(x,mean=0,sd=1)) + xlim(-4,4) + ylab("f(y)") + xlab("y") + geom_polygon(alpha=.8) + scale_fill_discrete(name="interval",labels = parse_format()) + theme(legend.title=element_text("interval"))
```

Because the Normal distribution is symmetric, with a single peak in the middle at $\mu$, the parameter $\mu$ not only equals the mean, but also the median (50% of all values are lower than $\mu$, and 50% are higher), and the mode. 

If the judgements are on average correct, this implies that $\mu = 8848$. Alternatively, the average judgement might be biased, for instance because of the low anchor. If this is so, what would the average judgement be? It is difficult to make a clear prediction about this. As for Paul's probability of a correct prediction if he were (somewhat) psychic, we can then simply assume that this parameter can have any value.

Before we continue, let's introduce some new notation. As before, we will use $Y$ to denote the dependent variable (i.e. people's judgements of the height of Mount Everest), and $Y_i$ to denote the $i$-th value of the dependent variable (i.e. the judgement by participant $i$), where $i=1,\ldots,n$. We will state the assumption that $Y$ follows a Normal distribution as
$$Y_i \sim \mathbf{Normal}(\mu,\sigma)$$
You can read this as "$Y_i$ is sampled from a Normal distribution with mean $\mu$ and standard deviation $\sigma$". So the tilde ($\sim$) stands for "sampled from". When we denote distributions, such as the Normal distribution, we will use a bold font for the name of the distribution, and between the parentheses that follow we will indicate the parameters of the distribution.

Using this notation, we can describe our two alternative models for people's judgements as:

- MODEL R: $\quad Y_i \sim \mathbf{Normal}(8848, \sigma)$
- MODEL G: $\quad Y_i \sim \mathbf{Normal}(\mu, \sigma)$

MODEL R is the restricted model, a special case of the more general MODEL G. The restriction is on $\mu$. In MODEL G, $-\infty \leq \mu \leq \infty$ (remember that $\infty$ stands for _infinity_). MODEL R picks a specific value $\underline{\mu}$ from this infinite range, namely $\mu = 8848$. In both models, the standard deviation is unknown. Standard deviations, like variances, can never be negative, so $\sigma \geq 0$, but this is all that we will specify in advance for that parameter.

## Parameter estimation

MODEL G has two parameters: the mean $\mu$ and the standard deviation $\sigma$. The maximum likelihood estimate of $\mu$ is the sample mean:

\begin{equation}
\hat{\mu} = \overline{Y} = \frac{\sum_{i=1}^n Y_i}{n}
(\#eq:ml-estimator-mean-simple-model)
\end{equation}

The maximum likelihood estimate of the variance is the sample variance (Equation \@ref(eq:definition-sample-variance)) $\hat{\sigma}^2_\text{ML} = S^2$. However, this estimator of the variance is biased. It is therefore common to estimate the variance with the unbiased estimator:
\begin{equation}
\hat{\sigma}^2 = \frac{\sum_{i=1}^n (Y_i - \overline{Y})^2}{n-1}
(\#eq:unbiased-estimator-variance-simple-model)
\end{equation}
The difference is to divide the sum of squared deviations by $n-1$, rather than $n$. Intuitively, you can think of the reason for this as follows: When we use the sample mean $\overline{Y}$ rather than the true mean $\mu$ in computing the variance, we don't take into account that the sample mean is a noisy estimate of the true mean $\mu$. Compared to $\overline{Y}$, the true mean could be somewhat higher or lower, and therefore the sample variance is likely to be an underestimate of the true variance. In other words, it is biased. By dividing by $n-1$ instead of $n$, the resulting estimate is a little higher, which eliminates this bias. When $n$ is large (i.e. there are a large number of observations), there will be little difference between the unbiased estimate and the sample variance, but for small $n$ the difference will be more marked. 

Note that the estimator above is for $\sigma^2$ (sigma squared, i.e. sigma raised to the power of 2). If we want an estimator of the standard deviation, we can simply take the square-root to get the following estimator of $\sigma$:

$$\hat{\sigma} = \sqrt{\hat{\sigma}^2}$$

If the mean is known to equal a particular value, $\mu = \underline{\mu}$, as in MODEL R, then we should use that value $\underline{\mu}$ instead of $\overline{Y}$ to estimate the variance and standard deviation. The unbiased estimate of the standard deviation for MODEL R is
$$\hat{\sigma}_R = \sqrt{\frac{\sum_{i=1}^n (Y_i - \underline{\mu})^2}{n}}$$
Perhaps confusingly, we can now divide by $n$ instead of by $n-1$ to get an unbiased estimate. The reason for this is that when we know the true mean, there is no estimation error like we had for $\overline{Y}$, and hence no additional source of variability which would bias the estimate. 

Usually, the mean $\mu$ is of more interest than the standard deviation $\sigma$. The standard deviation (or equivalently, the variance) are often so-called _nuisance parameters_.

### Sampling distribution of the estimated mean

Remember that the estimator of the mean is an algorithm that provides estimates from data. Different data sets will give different estimates, even when these are generated from the same Data Generating Process. Our model of the Data Generating Process is the Normal distribution, which has two parameters: $\mu$ and $\sigma$. Let's pick some values for these parameters, so that we can use our model to simulate data. For instance, suppose the judgements are on average equal to the true value, so $\mu = 8848$. Individual judgements are quite variable, however, so let's take $\sigma = 2000$. Figure \@ref(fig:histogram-sampling-mean-simple) shows the distribution of the estimated mean of 10,000 data sets each consisting of $n=109$ observations (just like in the anchoring data). Also shown (as a dotted line) is the Normal distribution of the model we used to generate the data. Clearly, the estimated means are much less variable than the simulated judgements.

```{r histogram-sampling-mean-simple, fig.cap="Estimated means for 10000 simulated data sets of $n = 109$, drawn from a Normal distribution with mean 8848 and standard deviation 2000. The dotted line is represents the Normal distribution from which the data sets were generated, and the solid line the theoretical distribution of the estimated means."}
set.seed(145)
mu <- 8848
sigma <- 2000
n_sim <- 10000
n <- 109
sim <- matrix(rnorm(n*n_sim, mean=mu, sd = sigma),ncol=n)
estimates <- rowMeans(sim)
ggplot(data.frame(estimates=estimates),aes(x=estimates)) + geom_histogram(binwidth=20) + xlim(8848-+ 2000,8848 + 2000) + stat_function(fun = function(x) 
    dnorm(x, mean = 8848, sd = 2000) * 20 * 10000, linetype=2) + stat_function(fun = function(x) 
    dnorm(x, mean = 8848, sd = 2000/sqrt(109)) * 20 * 10000, linetype=1)

```

Simulating data and then looking at the resulting distribution of estimates is straightforward, but also noisy. Luckily, it is quite easy to derive the true distribution of the estimated means (i.e. the sample means). It is also a Normal distribution, with a mean equal to $\mu$ (so the estimator is  unbiased), and a standard deviation equal to $\frac{\sigma}{\sqrt{n}}$, i.e. the standard deviation of the dependent variable divided by $\sqrt{n}$. Dividing by $\sqrt{n}$ implies that the standard deviation of the sample means is smaller than the standard deviation of the dependent variable. And, as $n$ increases, it becomes smaller and smaller, so the estimator is consistent. Using our new notation, we can write the sampling distribution of the estimated means as
\begin{equation}
\overline{Y} \sim \mathbf{Normal}(\mu, \frac{\sigma}{\sqrt{n}})
(\#eq:sampling-distribution-mean-simple)
\end{equation}
The standard deviation of the sampling distribution of estimates is also called the __standard error__ of the estimates.

To simulate judgements, we had to pick an arbitrary value of $\sigma$. But how can we simulate the data when $\sigma$ is unknown. We could of course use the unbiased estimate $\hat{\sigma}$. For MODEL R and the present data, that would be $\hat{\sigma} = `r sqrt(sum((dat$everest_meters - 8848)^2)/nrow(dat))`$, which is obviously substantially larger than 2000. If we'd use this value to simulate data sets and look at the distribution of the sample mean, we'd get a similar plot to the one of Figure \@ref(fig:histogram-sampling-mean-simple), but with a larger standard deviation. 

Suppose that MODEL R is true, that the Data Generating Process indeed results in a Normal distribution of people's judgements with a mean $\mu = 8848$ and a standard deviation $\sigma$. If we knew the value of $\sigma$, then we'd know everything there is to know about the distribution of the DGP. And knowing this, we'd know everything there is to know about the distribution of the sample means. But we don't know $\sigma$. While it makes sense to use an estimate of $\sigma$, this estimate will be noisy. We shouldn't just pretend that our estimate $\hat{\sigma}$ is identical to the true $\sigma$. The problem is that different values of $\sigma$ lead to different sampling distributions of the mean. Key to working out the sampling distribution of the mean when $\sigma$ is unknown is to also take into account the sampling distribution of the estimates of $\sigma$. Roughly, the idea is that, for a given data set, we can work out how likely different values of $\sigma$ are, and we can then derive the average of all the Normal distributions that follow from each possible value of $\sigma$. The resulting distribution is not a Normal distribution. It was derived by William Sealy Gosset  (1876â€“1937) in 1904. Gosset worked as Head Experimental Brewer for Guinness in Dublin, and the company had a rule forbidding their chemists to publish their findings [@zabell2008student]. Gosset was able to convince his boss that his mathematical work was of no practical use to competing brewers, and was allowed to publish them in @student1908probable, but under a pseudonym to avoid his colleagues getting similar ideas. "Student" was the pseudonym chosen by the managing director of Guinness, and hence the distribution is now known as Student's t-distribution. 

```{r comparing-normal-and-t-simple, fig.cap=paste0("Student t-distribution which is the true sampling distribution of the mean under MODEL R with unknown $\\sigma$ (solid line) and the Normal distribution that would be the sampling distribution if it is known that $\\sigma = \\hat{\\sigma}$ (broken line). Note that these curves are drawn for the case of $n=10$ observations, to make the differences between the distributions more marked. For $n=",nrow(dat),"$, the t-distribution is almost identical to the Normal distribution.")}
mu <- 8848
sigma <- sqrt(sum((dat$everest_meters - mu)^2)/nrow(dat))
n <- 10
ggplot(data.frame(x=c(mu - 2*sigma,mu + 2*sigma),y=c(0,dnorm(mu,mean=mu,sd=sigma/sqrt(n)))),aes(x=x,y=y)) + stat_function(fun = function(x) dnorm((x-mu)/(sigma/sqrt(n))), linetype=2) + stat_function(fun = function(x) dt((x-mu)/(sigma/sqrt(n-1)), df=n-1), linetype=1) + ylab("density") + xlab("Height of Mount Everest in meters")
```

You can see a comparison of the t-distribution and the Normal distribution in Figure \@ref(fig:comparing-normal-and-t-simple). The main thing to notice is that the t-distribution is also bell-shaped and symmetric, but it is wider (has fatter tails) than the Normal distribution. The difference between the t-distribution and Normal distribution depends on the value of $n-1$. When $n>30$, the difference is, for most practical purposes, negligible.

## Testing whether $\mu$ has an specific value

Now we know what happens to 

### The classical way

\begin{equation}
t = \frac{\hat{\mu} - \underline{\mu}}{\hat{\sigma}/\sqrt{n}} = \frac{\overline{Y} - \underset{\sim}{\mu}}{S/\sqrt{n}}
\end{equation}

This is also called a one-sample t-test. 

#### Two-tailed and one-tailed tests

### The model comparison way

## Confidence intervals

You can view a particularly nice animation of the confidence intervals on the [Seeing Theory](https://seeing-theory.brown.edu/frequentist-inference/index.html#section2) website.


## Assumptions


## The Central Limit Theorem

A main reason that the Normal distribution is used so often (and perhaps called "Normal", rather than "Abnormal"), is due to a mathematical fact known as the __Central Limit Theorem__:

```{definition, clt, name="Central Limit Theorem", echo=TRUE} 
The distribution of the sum of $n$ independent variables approaches the Normal distribution as the number of variables approaches infinity ($n \rightarrow \infty$).

```


This is quite an amazing theorem. Although you might wonder why you should care about sums of an infinite number of random variables, there are two things to note. Firstly, the rate at which the distribution "approaches" the normal distribution can be relatively quick. Secondly, the sample mean can be viewed as the (normalized) sum of $n$ variables:

$$\overline{Y} = \frac{1}{n} \sum_{i=1}^n Y_i$$

So the central limit theorem implies that as long as the number of samples is large enough, the sample mean will follow a Normal distribution.

### The Central Limit Theorem in action

To see the central limit theorem in action, let's pick an arbitrary probability distribution over 5 values, as shown in Figure \@ref(fig:weird-prob-dist). This will be the true distribution (i.e. the Data Generating Process) from which we can sample values.   

```{r weird-prob-dist,fig.cap="An aribitrary probability distribution over 5 values, clearly not a Normal distribution!",fig.width=4,fig.height=3,out.width="50%"}
library(dplyr)
library(tidyr)
library(purrr)

values <- c(1,2,3,4,5)
prob <- c(.5,.2,.1,.6,.3)
prob <- prob/sum(prob)

data.frame(value=values,probability=prob) %>% 
  ggplot(aes(x=value,y=probability)) + geom_col() + ylim(c(0,1))
```

When we repeatedly sample 5 values and calculate the mean, we can look at the distribution of these sampled means. This is shown in Figure \@ref(fig:clt-animation-1). Figure \@ref(fig:clt-animation-2) shows the same when we repeatedly sample 20 values and calculate the mean. 

```{r clt-animation-1, dev='png', echo=FALSE, cache=TRUE, fig.cap="The distribution of the mean of 5 samples (from the distribution in Figure XX", out.width='50%', fig.width=4}

library(gganimate)
library(dplyr)
library(tidyr)
library(purrr)

set.seed(345)
values <- c(1,2,3,4,5)
prob <- c(.5,.2,.1,.6,.3)
prob <- prob/sum(prob)

n <- 5
n_sim <- 200
clt_dat <- data.frame(sim=1:n_sim,size=n,outcome=sapply(1:n_sim,function(x) sum(sample(values,size=n,prob=prob,replace=TRUE))/n))

clt_dat %>%
  pull(sim) %>% 
    map_df(~ clt_dat %>% filter(sim %in% 1:.x) %>% mutate(sim = .x)) %>% 
  ggplot(aes(x=outcome)) + geom_histogram(binwidth=.2) + xlim(c(1,5)) + ylim(c(0,30)) + transition_manual(sim) + ease_aes("linear") + enter_fade() + exit_fade()

```

<!--
```{r clt-animation-2, dev='png',cache=TRUE, fig.cap="The distribution of the mean of 20 samples from the distribution in Figure XX"}

set.seed(567)
n_sim <- 1000
n <- 20
clt_dat <- data.frame(sim=1:n_sim,size=n,outcome=sapply(1:n_sim,function(x) sum(sample(values,size=n,prob=prob,replace=TRUE))/n))

clt_dat %>%
  pull(sim) %>% 
    map_df(~ clt_dat %>% filter(sim %in% 1:.x) %>% mutate(sim = .x)) %>%
  ggplot(aes(x=outcome)) + geom_histogram(binwidth=.05) + xlim(c(1,5)) + ylim(c(0,75)) + transition_manual(sim) + ease_aes("linear") + enter_fade() + exit_fade()
```
-->

So according to the Central Limit Theorem, if we focus on the mean of a sufficiently large number of independent observations, we can reasonably assume that the sampling distribution of the mean will follow a Normal distribution, even if the distribution from which the actual values were drawn is far from Normal. We might also imagine that if a variable is the outcome of a process in which lots of independent sources of noise are added, that the resulting variable will follow a Normal distribution. [todo: add example]

<!--
http://www.stats.ox.ac.uk/~dlunn/b8_02/b8pdf_8.pdf
http://www.stat.ucla.edu/~hqxu/stat105/pdf/ch09.pdf
https://www.math.arizona.edu/~jwatkins/v-anova.pdf
-->

There is an equivalent way to perform the hypothesis test that $\mu = \underline{\mu}$, by comparing two versions of a statistical model, one in which we assume we know the value of $\mu$ to be $\underline{\mu}$ (Model R), and one in which we don't (Model G). As we did for Paul the Octopus, we then look at the likelihood ratio to see whether Model R is tenable. Note that in both models, the standard deviation is considered unknown and will have to be estimated. 



<!-- 
## The General Linear Model

$$Y_i = \beta_0 + \beta_1 X_{1i} + \ldots + \beta_K X_{Ki} + \epsilon_i \quad \quad \epsilon_i \sim N(0,\sigma^2)$$
-->
