<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Simple linear regression | Statistics: data analysis and modelling</title>
  <meta name="description" content="A book about statistics for data analysis, with a main focus on statistical modelling." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Simple linear regression | Statistics: data analysis and modelling" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A book about statistics for data analysis, with a main focus on statistical modelling." />
  <meta name="github-repo" content="mspeekenbrink/sdam-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Simple linear regression | Statistics: data analysis and modelling" />
  
  <meta name="twitter:description" content="A book about statistics for data analysis, with a main focus on statistical modelling." />
  

<meta name="author" content="Maarten Speekenbrink" />


<meta name="date" content="2020-10-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="a-model-with-a-mean-one-sample-t-test.html"/>
<link rel="next" href="multiple-regression.html"/>
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="book_assets/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="book_assets/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="book_assets/viz-1.8.2/viz.js"></script>
<link href="book_assets/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="book_assets/grViz-binding-1.0.6.1/grViz.js"></script>
<script src="book_assets/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="book_assets/typedarray-0.1/typedarray.min.js"></script>
<link href="book_assets/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="book_assets/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="book_assets/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="book_assets/plotly-main-1.52.2/plotly-latest.min.js"></script>



<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#notation"><i class="fa fa-check"></i>Notation</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#paul-the-octopus"><i class="fa fa-check"></i><b>1.1</b> Paul the octopus</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#experiments-and-observations"><i class="fa fa-check"></i><b>1.2</b> Experiments and observations</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#data"><i class="fa fa-check"></i><b>1.3</b> Data</a><ul>
<li class="chapter" data-level="1.3.1" data-path="intro.html"><a href="intro.html#measurement-scales"><i class="fa fa-check"></i><b>1.3.1</b> Measurement scales</a></li>
<li class="chapter" data-level="1.3.2" data-path="intro.html"><a href="intro.html#the-data-generating-process"><i class="fa fa-check"></i><b>1.3.2</b> The Data Generating Process</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#exploring-and-describing-data"><i class="fa fa-check"></i><b>1.4</b> Exploring and describing data</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#summary-statistics"><i class="fa fa-check"></i><b>1.4.1</b> Summary statistics</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#visual-exploration"><i class="fa fa-check"></i><b>1.4.2</b> Visual exploration</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#analysis-and-modelling"><i class="fa fa-check"></i><b>1.5</b> Analysis and modelling</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#summary"><i class="fa fa-check"></i><b>1.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistical-modelling.html"><a href="statistical-modelling.html"><i class="fa fa-check"></i><b>2</b> Statistical modelling</a><ul>
<li class="chapter" data-level="2.1" data-path="statistical-modelling.html"><a href="statistical-modelling.html#coin-flipping-defining-a-statistical-model"><i class="fa fa-check"></i><b>2.1</b> Coin flipping: Defining a statistical model</a></li>
<li class="chapter" data-level="2.2" data-path="statistical-modelling.html"><a href="statistical-modelling.html#probability"><i class="fa fa-check"></i><b>2.2</b> Probability</a><ul>
<li class="chapter" data-level="2.2.1" data-path="statistical-modelling.html"><a href="statistical-modelling.html#what-is-probability"><i class="fa fa-check"></i><b>2.2.1</b> What is probability?</a></li>
<li class="chapter" data-level="2.2.2" data-path="statistical-modelling.html"><a href="statistical-modelling.html#distributions"><i class="fa fa-check"></i><b>2.2.2</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="statistical-modelling.html"><a href="statistical-modelling.html#flipping-a-biased-coin-an-alternative-model"><i class="fa fa-check"></i><b>2.3</b> Flipping a biased coin: An alternative model</a></li>
<li class="chapter" data-level="2.4" data-path="statistical-modelling.html"><a href="statistical-modelling.html#estimation"><i class="fa fa-check"></i><b>2.4</b> Estimation</a><ul>
<li class="chapter" data-level="2.4.1" data-path="statistical-modelling.html"><a href="statistical-modelling.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>2.4.1</b> Maximum likelihood estimation</a></li>
<li class="chapter" data-level="2.4.2" data-path="statistical-modelling.html"><a href="statistical-modelling.html#properties-of-good-estimators"><i class="fa fa-check"></i><b>2.4.2</b> Properties of good estimators</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="statistical-modelling.html"><a href="statistical-modelling.html#comparing-models-null-hypothesis-significance-testing"><i class="fa fa-check"></i><b>2.5</b> Comparing models: Null-hypothesis significance testing</a><ul>
<li class="chapter" data-level="2.5.1" data-path="statistical-modelling.html"><a href="statistical-modelling.html#decisions-and-types-of-error"><i class="fa fa-check"></i><b>2.5.1</b> Decisions and types of error</a></li>
<li class="chapter" data-level="2.5.2" data-path="statistical-modelling.html"><a href="statistical-modelling.html#significance-and-power"><i class="fa fa-check"></i><b>2.5.2</b> Significance and power</a></li>
<li class="chapter" data-level="2.5.3" data-path="statistical-modelling.html"><a href="statistical-modelling.html#testing-whether-paul-was-guessing"><i class="fa fa-check"></i><b>2.5.3</b> Testing whether Paul was guessing</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="statistical-modelling.html"><a href="statistical-modelling.html#hypothesis-testing-directly-with-the-binomial-distribution"><i class="fa fa-check"></i><b>2.6</b> Hypothesis testing directly with the Binomial distribution</a></li>
<li class="chapter" data-level="2.7" data-path="intro.html"><a href="intro.html#summary"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="statistical-modelling.html"><a href="statistical-modelling.html#epilogue"><i class="fa fa-check"></i><b>2.8</b> Epilogue</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html"><i class="fa fa-check"></i><b>3</b> A model with a mean (one sample t-test)</a><ul>
<li class="chapter" data-level="3.1" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#numeric-judgement-and-anchoring"><i class="fa fa-check"></i><b>3.1</b> Numeric judgement and anchoring</a><ul>
<li class="chapter" data-level="3.1.1" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#exploring-the-data"><i class="fa fa-check"></i><b>3.1.1</b> Exploring the data</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#a-statistical-model-of-judgements"><i class="fa fa-check"></i><b>3.2</b> A statistical model of judgements</a><ul>
<li class="chapter" data-level="3.2.1" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#the-normal-distribution"><i class="fa fa-check"></i><b>3.2.1</b> The Normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#parameter-estimation"><i class="fa fa-check"></i><b>3.3</b> Parameter estimation</a><ul>
<li class="chapter" data-level="3.3.1" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#sampling-distribution-of-the-estimated-mean"><i class="fa fa-check"></i><b>3.3.1</b> Sampling distribution of the estimated mean</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#testing-whether-mu-has-an-specific-value"><i class="fa fa-check"></i><b>3.4</b> Testing whether <span class="math inline">\(\mu\)</span> has an specific value</a><ul>
<li class="chapter" data-level="3.4.1" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#the-classical-way"><i class="fa fa-check"></i><b>3.4.1</b> The classical way</a></li>
<li class="chapter" data-level="3.4.2" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#the-model-comparison-way"><i class="fa fa-check"></i><b>3.4.2</b> The model comparison way</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#confidence-intervals"><i class="fa fa-check"></i><b>3.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="3.6" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#assumptions"><i class="fa fa-check"></i><b>3.6</b> Assumptions</a></li>
<li class="chapter" data-level="3.7" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.7</b> The Central Limit Theorem</a><ul>
<li class="chapter" data-level="3.7.1" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#the-central-limit-theorem-in-action"><i class="fa fa-check"></i><b>3.7.1</b> The Central Limit Theorem in action</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>4</b> Simple linear regression</a><ul>
<li class="chapter" data-level="4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#voting-and-hate-groups"><i class="fa fa-check"></i><b>4.1</b> Voting and hate groups</a></li>
<li class="chapter" data-level="4.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-model"><i class="fa fa-check"></i><b>4.2</b> The model</a></li>
<li class="chapter" data-level="4.3" data-path="statistical-modelling.html"><a href="statistical-modelling.html#estimation"><i class="fa fa-check"></i><b>4.3</b> Estimation</a></li>
<li class="chapter" data-level="4.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.4</b> Hypothesis testing</a><ul>
<li class="chapter" data-level="4.4.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#sampling-distribution-of-estimates"><i class="fa fa-check"></i><b>4.4.1</b> Sampling distribution of estimates</a></li>
<li class="chapter" data-level="4.4.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#model-comparison"><i class="fa fa-check"></i><b>4.4.2</b> Model comparison</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="a-model-with-a-mean-one-sample-t-test.html"><a href="a-model-with-a-mean-one-sample-t-test.html#confidence-intervals"><i class="fa fa-check"></i><b>4.5</b> Confidence intervals</a></li>
<li class="chapter" data-level="4.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#assumptions-and-outliers"><i class="fa fa-check"></i><b>4.6</b> Assumptions and outliers</a></li>
<li class="chapter" data-level="4.7" data-path="intro.html"><a href="intro.html#summary"><i class="fa fa-check"></i><b>4.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>5</b> Multiple regression</a><ul>
<li class="chapter" data-level="5.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-model"><i class="fa fa-check"></i><b>5.1</b> The model</a></li>
<li class="chapter" data-level="5.2" data-path="statistical-modelling.html"><a href="statistical-modelling.html#estimation"><i class="fa fa-check"></i><b>5.2</b> Estimation</a></li>
<li class="chapter" data-level="5.3" data-path="multiple-regression.html"><a href="multiple-regression.html#inference"><i class="fa fa-check"></i><b>5.3</b> Inference</a></li>
<li class="chapter" data-level="5.4" data-path="multiple-regression.html"><a href="multiple-regression.html#multicollinearity"><i class="fa fa-check"></i><b>5.4</b> Multicollinearity</a></li>
<li class="chapter" data-level="5.5" data-path="multiple-regression.html"><a href="multiple-regression.html#polynomial-regression"><i class="fa fa-check"></i><b>5.5</b> Polynomial regression</a></li>
<li class="chapter" data-level="5.6" data-path="intro.html"><a href="intro.html#summary"><i class="fa fa-check"></i><b>5.6</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="moderation-and-mediation.html"><a href="moderation-and-mediation.html"><i class="fa fa-check"></i><b>6</b> Moderation and mediation</a><ul>
<li class="chapter" data-level="6.1" data-path="moderation-and-mediation.html"><a href="moderation-and-mediation.html#moderated-regression"><i class="fa fa-check"></i><b>6.1</b> Moderated regression</a></li>
<li class="chapter" data-level="6.2" data-path="moderation-and-mediation.html"><a href="moderation-and-mediation.html#mediation"><i class="fa fa-check"></i><b>6.2</b> Mediation</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="a-model-of-means-anova.html"><a href="a-model-of-means-anova.html"><i class="fa fa-check"></i><b>7</b> A model of means (ANOVA)</a><ul>
<li class="chapter" data-level="7.1" data-path="a-model-of-means-anova.html"><a href="a-model-of-means-anova.html#two-sample-t-test"><i class="fa fa-check"></i><b>7.1</b> Two-sample t-test</a></li>
<li class="chapter" data-level="7.2" data-path="a-model-of-means-anova.html"><a href="a-model-of-means-anova.html#contrast-coding"><i class="fa fa-check"></i><b>7.2</b> Contrast coding</a></li>
<li class="chapter" data-level="7.3" data-path="a-model-of-means-anova.html"><a href="a-model-of-means-anova.html#oneway-anova"><i class="fa fa-check"></i><b>7.3</b> Oneway ANOVA</a></li>
<li class="chapter" data-level="7.4" data-path="a-model-of-means-anova.html"><a href="a-model-of-means-anova.html#factorial-anova"><i class="fa fa-check"></i><b>7.4</b> Factorial ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mixing-categorical-and-metric-predictors-ancova.html"><a href="mixing-categorical-and-metric-predictors-ancova.html"><i class="fa fa-check"></i><b>8</b> Mixing categorical and metric predictors (ANCOVA)</a></li>
<li class="chapter" data-level="9" data-path="repeated-measures-anova.html"><a href="repeated-measures-anova.html"><i class="fa fa-check"></i><b>9</b> Repeated-measures ANOVA</a></li>
<li class="chapter" data-level="10" data-path="linear-mixed-effects-models.html"><a href="linear-mixed-effects-models.html"><i class="fa fa-check"></i><b>10</b> Linear mixed-effects models</a></li>
<li class="chapter" data-level="11" data-path="introduction-to-bayesian-hypothesis-testing.html"><a href="introduction-to-bayesian-hypothesis-testing.html"><i class="fa fa-check"></i><b>11</b> Introduction to Bayesian hypothesis testing</a></li>
<li class="chapter" data-level="12" data-path="being-a-responsible-data-analyst.html"><a href="being-a-responsible-data-analyst.html"><i class="fa fa-check"></i><b>12</b> Being a responsible data analyst</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics: data analysis and modelling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-linear-regression" class="section level1">
<h1><span class="header-section-number">Chapter 4</span> Simple linear regression</h1>
<div id="voting-and-hate-groups" class="section level2">
<h2><span class="header-section-number">4.1</span> Voting and hate groups</h2>
<p>Donald Trump is perhaps the most divisive president in American history. The 2016 US elections were mired in controversy.</p>
<div class="figure" style="text-align: center"><span id="fig:scatterplot-trump-votes-hate-groups"></span>
<div id="htmlwidget-b38adca41469f51a3e50" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-b38adca41469f51a3e50">{"x":{"data":[{"x":[5.55,0,2.6,5.35,2.01,2.89,1.4,4.2,3.06,3.1,0,7.13,2.5,3.92,1.28,2.41,5.18,2.99,2.25,2.99,1.76,2.82,1.81,6.02,3.94,9.59,2.62,1.36,4.5,1.68,0.96,2.38,3.06,1.32,3.01,1.53,2.69,3.13,0.95,2.42,8.09,5.71,1.97,0.98,1.6,4.64,2.88,2.18,1.56,3.42],"y":[62.9,52.9,49.5,60.4,32.7,44.4,41.2,41.9,49.1,51.3,30,59.2,39.4,57.2,51.8,57.2,62.5,58.1,45.2,35.3,33.5,47.6,45.4,58.3,57.1,56.5,60.3,45.5,47.2,41.8,40,37.5,50.5,64.1,52.1,65.3,41.1,48.8,39.8,54.9,61.5,61.1,52.6,45.9,32.6,45,38.2,68.7,47.9,70.1],"text":["hate_groups_per_million: 5.55<br />percent_Trump_votes: 62.9<br />state: Alabama","hate_groups_per_million: 0.00<br />percent_Trump_votes: 52.9<br />state: Alaska","hate_groups_per_million: 2.60<br />percent_Trump_votes: 49.5<br />state: Arizona","hate_groups_per_million: 5.35<br />percent_Trump_votes: 60.4<br />state: Arkansas","hate_groups_per_million: 2.01<br />percent_Trump_votes: 32.7<br />state: California","hate_groups_per_million: 2.89<br />percent_Trump_votes: 44.4<br />state: Colorado","hate_groups_per_million: 1.40<br />percent_Trump_votes: 41.2<br />state: Connecticut","hate_groups_per_million: 4.20<br />percent_Trump_votes: 41.9<br />state: Delaware","hate_groups_per_million: 3.06<br />percent_Trump_votes: 49.1<br />state: Florida","hate_groups_per_million: 3.10<br />percent_Trump_votes: 51.3<br />state: Georgia","hate_groups_per_million: 0.00<br />percent_Trump_votes: 30.0<br />state: Hawaii","hate_groups_per_million: 7.13<br />percent_Trump_votes: 59.2<br />state: Idaho","hate_groups_per_million: 2.50<br />percent_Trump_votes: 39.4<br />state: Illinois","hate_groups_per_million: 3.92<br />percent_Trump_votes: 57.2<br />state: Indiana","hate_groups_per_million: 1.28<br />percent_Trump_votes: 51.8<br />state: Iowa","hate_groups_per_million: 2.41<br />percent_Trump_votes: 57.2<br />state: Kansas","hate_groups_per_million: 5.18<br />percent_Trump_votes: 62.5<br />state: Kentucky","hate_groups_per_million: 2.99<br />percent_Trump_votes: 58.1<br />state: Louisiana","hate_groups_per_million: 2.25<br />percent_Trump_votes: 45.2<br />state: Maine","hate_groups_per_million: 2.99<br />percent_Trump_votes: 35.3<br />state: Maryland","hate_groups_per_million: 1.76<br />percent_Trump_votes: 33.5<br />state: Massachusetts","hate_groups_per_million: 2.82<br />percent_Trump_votes: 47.6<br />state: Michigan","hate_groups_per_million: 1.81<br />percent_Trump_votes: 45.4<br />state: Minnesota","hate_groups_per_million: 6.02<br />percent_Trump_votes: 58.3<br />state: Mississippi","hate_groups_per_million: 3.94<br />percent_Trump_votes: 57.1<br />state: Missouri","hate_groups_per_million: 9.59<br />percent_Trump_votes: 56.5<br />state: Montana","hate_groups_per_million: 2.62<br />percent_Trump_votes: 60.3<br />state: Nebraska","hate_groups_per_million: 1.36<br />percent_Trump_votes: 45.5<br />state: Nevada","hate_groups_per_million: 4.50<br />percent_Trump_votes: 47.2<br />state: New Hampshire","hate_groups_per_million: 1.68<br />percent_Trump_votes: 41.8<br />state: New Jersey","hate_groups_per_million: 0.96<br />percent_Trump_votes: 40.0<br />state: New Mexico","hate_groups_per_million: 2.38<br />percent_Trump_votes: 37.5<br />state: New York","hate_groups_per_million: 3.06<br />percent_Trump_votes: 50.5<br />state: North Carolina","hate_groups_per_million: 1.32<br />percent_Trump_votes: 64.1<br />state: North Dakota","hate_groups_per_million: 3.01<br />percent_Trump_votes: 52.1<br />state: Ohio","hate_groups_per_million: 1.53<br />percent_Trump_votes: 65.3<br />state: Oklahoma","hate_groups_per_million: 2.69<br />percent_Trump_votes: 41.1<br />state: Oregon","hate_groups_per_million: 3.13<br />percent_Trump_votes: 48.8<br />state: Pennsylvania","hate_groups_per_million: 0.95<br />percent_Trump_votes: 39.8<br />state: Rhode Island","hate_groups_per_million: 2.42<br />percent_Trump_votes: 54.9<br />state: South Carolina","hate_groups_per_million: 8.09<br />percent_Trump_votes: 61.5<br />state: South Dakota","hate_groups_per_million: 5.71<br />percent_Trump_votes: 61.1<br />state: Tennessee","hate_groups_per_million: 1.97<br />percent_Trump_votes: 52.6<br />state: Texas","hate_groups_per_million: 0.98<br />percent_Trump_votes: 45.9<br />state: Utah","hate_groups_per_million: 1.60<br />percent_Trump_votes: 32.6<br />state: Vermont","hate_groups_per_million: 4.64<br />percent_Trump_votes: 45.0<br />state: Virginia","hate_groups_per_million: 2.88<br />percent_Trump_votes: 38.2<br />state: Washington","hate_groups_per_million: 2.18<br />percent_Trump_votes: 68.7<br />state: West Virginia","hate_groups_per_million: 1.56<br />percent_Trump_votes: 47.9<br />state: Wisconsin","hate_groups_per_million: 3.42<br />percent_Trump_votes: 70.1<br />state: Wyoming"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(0,0,0,1)","opacity":1,"size":5.66929133858268,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":26.2283105022831,"r":7.30593607305936,"b":40.1826484018265,"l":37.2602739726027},"plot_bgcolor":"rgba(235,235,235,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.4795,10.0695],"tickmode":"array","ticktext":["0.0","2.5","5.0","7.5","10.0"],"tickvals":[0,2.5,5,7.5,10],"categoryorder":"array","categoryarray":["0.0","2.5","5.0","7.5","10.0"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":{"text":"Hate groups per million citizens","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[27.995,72.105],"tickmode":"array","ticktext":["30","40","50","60","70"],"tickvals":[30,40,50,60,70],"categoryorder":"array","categoryarray":["30","40","50","60","70"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":{"text":"% votes fpr Trump","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"2e826b0330e0":{"x":{},"y":{},"name":{},"type":"scatter"}},"cur_data":"2e826b0330e0","visdat":{"2e826b0330e0":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p class="caption">
Figure 4.1: Percentage of votes for Trump in the 2016 elections for 50 US states and the number of hate groups per 1 million citizens
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:boxplots-trump-votes-hate-groups"></span>
<img src="_main_files/figure-html/boxplots-trump-votes-hate-groups-1.svg" alt="Violin-boxplots for percentage of votes for Trump in the 2016 elections for 50 US states and the number of hate groups per 1 million citizens" width="50%" /><img src="_main_files/figure-html/boxplots-trump-votes-hate-groups-2.svg" alt="Violin-boxplots for percentage of votes for Trump in the 2016 elections for 50 US states and the number of hate groups per 1 million citizens" width="50%" />
<p class="caption">
Figure 4.2: Violin-boxplots for percentage of votes for Trump in the 2016 elections for 50 US states and the number of hate groups per 1 million citizens
</p>
</div>
<p>To assess the relation between Trump votes and hate groups, we will use a linear regression model. As the name suggests, this model involves a line, a straight one in fact. This straight line represents the predicted value of the dependent variable <span class="math inline">\(Y\)</span> (i.e. the percentage of Trump votes) for each value of the predictor (or independent) variable <span class="math inline">\(X\)</span> (i.e. the number of hate groups). The model allows the predictions to be wrong by incorporating an error term,</p>
</div>
<div id="the-model" class="section level2">
<h2><span class="header-section-number">4.2</span> The model</h2>
<p>The bivariate regression model can be defined as follows:
<span class="math display" id="eq:bivariate-regression-model-definition">\[\begin{equation}
Y_i = \beta_0 + \beta_1 X_{i} + \epsilon_i \quad \quad \quad \epsilon_i \sim \mathbf{Normal}(0,\sigma)
\tag{4.1}
\end{equation}\]</span></p>
<ul>
<li>The <strong>intercept</strong> <span class="math inline">\(\beta_0\)</span> is</li>
<li>The <strong>slope</strong> <span class="math inline">\(\beta_1\)</span> is</li>
<li>The <strong>error</strong> or <strong>residual</strong> <span class="math inline">\(\epsilon_i\)</span></li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:simple-regression-explanation-plot"></span>
<img src="_main_files/figure-html/simple-regression-explanation-plot-1.svg" alt="The simple regression model. Left: The intercept is the predicted value of Y when X=0 and is point at which the regression line crosses the y-axis. The slope determines the steepness of the regression line and represents the increase (or decrease) in the predicted Y-value for every 1-unit increase in X. Right: the error terms or residuals are the vertical distances of each observed Y-value from the regression line" width="50%" /><img src="_main_files/figure-html/simple-regression-explanation-plot-2.svg" alt="The simple regression model. Left: The intercept is the predicted value of Y when X=0 and is point at which the regression line crosses the y-axis. The slope determines the steepness of the regression line and represents the increase (or decrease) in the predicted Y-value for every 1-unit increase in X. Right: the error terms or residuals are the vertical distances of each observed Y-value from the regression line" width="50%" />
<p class="caption">
Figure 4.3: The simple regression model. Left: The intercept is the predicted value of Y when X=0 and is point at which the regression line crosses the y-axis. The slope determines the steepness of the regression line and represents the increase (or decrease) in the predicted Y-value for every 1-unit increase in X. Right: the error terms or residuals are the vertical distances of each observed Y-value from the regression line
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:simple-regression-distribution-error-plot"></span>
<img src="_main_files/figure-html/simple-regression-distribution-error-plot-1.svg" alt="The errors in a regression model are assumed to follow a Normal distribution around the regression line." width="50%" />
<p class="caption">
Figure 4.4: The errors in a regression model are assumed to follow a Normal distribution around the regression line.
</p>
</div>
</div>
<div id="estimation" class="section level2">
<h2><span class="header-section-number">4.3</span> Estimation</h2>
<p>The maximum likelihood estimates of the model parameters are
<span class="math display" id="eq:simple-regression-intercept-estimate">\[\begin{equation} 
\hat{\beta}_0 = \overline{Y} - \hat{\beta}_1 \overline{X} ,
\tag{4.2}
\end{equation}\]</span>
for the intercept, and
<span class="math display" id="eq:simple-regression-slope-estimate">\[\begin{equation}
\hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \overline{X})(Y_i - \overline{Y})}{\sum_{i=1}^n (X_i - \overline{X})^2} .
\tag{4.3}
\end{equation}\]</span>
for the slope. Note that to estimate the intercept, we need the estimate of the slope. Let’s focus on
the estimate of the slope first. The top part of the division (the numerator) contains a sum of
deviations of the predictor values (<span class="math inline">\(X_i\)</span>) from its average (<span class="math inline">\(\overline{X}\)</span>) multiplied by deviations
of the values <span class="math inline">\(Y_i\)</span> of the dependent variable from its average (<span class="math inline">\(\overline{Y}\)</span>). Let’s consider these
multiplied deviations a little further. Each deviation is positive (larger than 0) when the value is
higher than the average, and negative (smaller than 0), when the value is lower than the average.
So the multiplied deviations are positive whenever both values are larger than their average, and
whenever both values are below their average (a negative value multiplied by another negative value
is positive). If we were to divide the sum of the multiplied deviations by <span class="math inline">\(n\)</span> (the number of observations),
we’d get the average of these multiplied deviations. This average is also called the <strong>covariance</strong> between
<span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>:
<span class="math display">\[\text{Cov}(X,Y) =  \frac{\sum_{i=1}^n (X_i - \overline{X})(Y_i - \overline{Y})}{n}\]</span>
Note that, as an estimator, this provides biased estimates of the true covariance. An unbiased estimator
of the true covariance is obtained by dividing by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span> (just as for the variance). Going back to our example, the covariance between trump votes and hate groups would be positive whenever states with higher-than-average Trump votes are generally also states with higher-than-average hate groups, and whenever
states with lower-than-average Trump votes are generally also states with lower-than-average hate groups.
The covariance would be negative, on the other hand, whenever states with higher-than-average Trump votes are generally states with lower-than-average hate groups, and whenever
states with lower-than-average Trump votes are generally states with higher-than-average hate groups. A positive or negative covariance is indicative of a relation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Indeed, the well-known
Pearson correlation coefficient is a standardized covariance, where the standardization scales the correlation
to always be between -1 and 1 and involves dividing the covariance by the product of the standard deviations
of both variables:
<span class="math display">\[\begin{align}
r_{X,Y} &amp;= \frac{\text{Cov}(X,Y)}{S_X \times S_Y} \\
&amp;= \frac{\frac{\sum_{i=1}^n (X_i - \overline{X})(Y_i - \overline{Y})}{n}}{\sqrt{\frac{\sum_{i=1}^n (X_i - \overline{X})^2}{n}} \times \sqrt{\frac{\sum_{i=1}^n (Y_i - \overline{Y})^2}{n}}}
\end{align}\]</span></p>
<p>Going back to the estimate of the slope (Equation <a href="simple-linear-regression.html#eq:simple-regression-slope-estimate">(4.3)</a>), we can view this as a different way of standardizing the covariance. Looking at the bottom part of the division (the denominator), we can see it consists of the sum of squared deviations of the predictor values from its mean. If we were to divide this sum by the number of observations, we’d get the variance of <span class="math inline">\(X\)</span>. As dividing both the top part (numerator) and bottom part (denominator) in a division by the same value does not affect the outcome of the division (i.e. <span class="math inline">\(\frac{a}{b} = \frac{a/c}{b/c}\)</span>), we can choose to divide both by <span class="math inline">\(n\)</span> so the numerator becomes the covariance and the denominator the variance (we could also divide both by <span class="math inline">\(n-1\)</span> so they become unbiased estimators of the covariance and variance). So an alternative way of computing the estimate of the slope is
<span class="math display">\[\hat{\beta}_1 = \frac{\text{Cov}(X,Y)}{\text{Var}(X)}\]</span>
Note that the variance of <span class="math inline">\(X\)</span> equals the product of the standard deviation of <span class="math inline">\(X\)</span> and itself, as <span class="math inline">\(S^2_X = S_X \times S_X\)</span>. So the slope estimate looks quite a bit like the correlation coefficient, where instead of the standard deviation of <span class="math inline">\(Y\)</span>, we use the standard deviation of <span class="math inline">\(X\)</span> twice. With a little algebraic manipulation, we can also state the slope estimate in terms of the correlation as
<span class="math display">\[\hat{\beta}_1 = \frac{S_Y}{S_X} r_{X,Y}\]</span>
The reason for going into these alternative formulations is not to pain or confuse you with lots of equations. What these alternative formulations show is that the slope tells us something about the relation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, just like the covariance and correlation do. If the sample correlation is 0, then so is the estimated slope. It is important to realise that we have been discussing the <em>estimate</em> of the slope, not the true value itself. But the same relations hold for the true values. If we denote the true correlation as <span class="math inline">\(\rho_{X,Y}\)</span>, then the true value of the slope can be defined as
<span class="math display">\[\beta_1 = \frac{\sigma_Y}{\sigma_X} \rho_{X,Y}\]</span>
The true value of the slope is 0 when the true correlation between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> equals <span class="math inline">\(\rho_{X,Y} = 0\)</span>. It would also be 0 if the true standard deviation of <span class="math inline">\(Y\)</span> equals <span class="math inline">\(\sigma_Y = 0\)</span>, but this implies that <span class="math inline">\(Y\)</span> is a constant and that is not a very interesting situation.</p>
<p>That was perhaps a little tortuous, and we haven’t even discussed the estimate of the intercept! Remember that the intercept represents the predicted value of <span class="math inline">\(Y\)</span> at the point where <span class="math inline">\(X=0\)</span>. It is the average value of <span class="math inline">\(Y\)</span> for all those cases where <span class="math inline">\(X=0\)</span>. This is often not so interesting, although in our example, we might be interested in what the average percentage of votes for Trump would be in places where there are no hate groups. Equation <a href="simple-linear-regression.html#eq:simple-regression-intercept-estimate">(4.2)</a> shows that we can estimate this value by adjusting the average of <span class="math inline">\(Y\)</span> by subtracting <span class="math inline">\(\hat{\beta}_1 \times \overline{X}\)</span> from it. How come? [TODO]</p>
<p>So, what are the estimates of the model predicting Trump votes by hate groups?</p>
<p><span class="math display">\[\texttt{trump_votes}_i = 42.897 + 2.3 \times \texttt{hate_groups} + e_i\]</span></p>
<div class="figure" style="text-align: center"><span id="fig:scatterplot-trump-votes-hate-groups-with-regression"></span>
<div id="htmlwidget-2653f0c7e43d58c47b84" style="width:672px;height:480px;" class="plotly html-widget"></div>
<script type="application/json" data-for="htmlwidget-2653f0c7e43d58c47b84">{"x":{"data":[{"x":[5.55,0,2.6,5.35,2.01,2.89,1.4,4.2,3.06,3.1,0,7.13,2.5,3.92,1.28,2.41,5.18,2.99,2.25,2.99,1.76,2.82,1.81,6.02,3.94,9.59,2.62,1.36,4.5,1.68,0.96,2.38,3.06,1.32,3.01,1.53,2.69,3.13,0.95,2.42,8.09,5.71,1.97,0.98,1.6,4.64,2.88,2.18,1.56,3.42],"y":[62.9,52.9,49.5,60.4,32.7,44.4,41.2,41.9,49.1,51.3,30,59.2,39.4,57.2,51.8,57.2,62.5,58.1,45.2,35.3,33.5,47.6,45.4,58.3,57.1,56.5,60.3,45.5,47.2,41.8,40,37.5,50.5,64.1,52.1,65.3,41.1,48.8,39.8,54.9,61.5,61.1,52.6,45.9,32.6,45,38.2,68.7,47.9,70.1],"text":["hate_groups_per_million: 5.55<br />percent_Trump_votes: 62.9<br />state: Alabama","hate_groups_per_million: 0.00<br />percent_Trump_votes: 52.9<br />state: Alaska","hate_groups_per_million: 2.60<br />percent_Trump_votes: 49.5<br />state: Arizona","hate_groups_per_million: 5.35<br />percent_Trump_votes: 60.4<br />state: Arkansas","hate_groups_per_million: 2.01<br />percent_Trump_votes: 32.7<br />state: California","hate_groups_per_million: 2.89<br />percent_Trump_votes: 44.4<br />state: Colorado","hate_groups_per_million: 1.40<br />percent_Trump_votes: 41.2<br />state: Connecticut","hate_groups_per_million: 4.20<br />percent_Trump_votes: 41.9<br />state: Delaware","hate_groups_per_million: 3.06<br />percent_Trump_votes: 49.1<br />state: Florida","hate_groups_per_million: 3.10<br />percent_Trump_votes: 51.3<br />state: Georgia","hate_groups_per_million: 0.00<br />percent_Trump_votes: 30.0<br />state: Hawaii","hate_groups_per_million: 7.13<br />percent_Trump_votes: 59.2<br />state: Idaho","hate_groups_per_million: 2.50<br />percent_Trump_votes: 39.4<br />state: Illinois","hate_groups_per_million: 3.92<br />percent_Trump_votes: 57.2<br />state: Indiana","hate_groups_per_million: 1.28<br />percent_Trump_votes: 51.8<br />state: Iowa","hate_groups_per_million: 2.41<br />percent_Trump_votes: 57.2<br />state: Kansas","hate_groups_per_million: 5.18<br />percent_Trump_votes: 62.5<br />state: Kentucky","hate_groups_per_million: 2.99<br />percent_Trump_votes: 58.1<br />state: Louisiana","hate_groups_per_million: 2.25<br />percent_Trump_votes: 45.2<br />state: Maine","hate_groups_per_million: 2.99<br />percent_Trump_votes: 35.3<br />state: Maryland","hate_groups_per_million: 1.76<br />percent_Trump_votes: 33.5<br />state: Massachusetts","hate_groups_per_million: 2.82<br />percent_Trump_votes: 47.6<br />state: Michigan","hate_groups_per_million: 1.81<br />percent_Trump_votes: 45.4<br />state: Minnesota","hate_groups_per_million: 6.02<br />percent_Trump_votes: 58.3<br />state: Mississippi","hate_groups_per_million: 3.94<br />percent_Trump_votes: 57.1<br />state: Missouri","hate_groups_per_million: 9.59<br />percent_Trump_votes: 56.5<br />state: Montana","hate_groups_per_million: 2.62<br />percent_Trump_votes: 60.3<br />state: Nebraska","hate_groups_per_million: 1.36<br />percent_Trump_votes: 45.5<br />state: Nevada","hate_groups_per_million: 4.50<br />percent_Trump_votes: 47.2<br />state: New Hampshire","hate_groups_per_million: 1.68<br />percent_Trump_votes: 41.8<br />state: New Jersey","hate_groups_per_million: 0.96<br />percent_Trump_votes: 40.0<br />state: New Mexico","hate_groups_per_million: 2.38<br />percent_Trump_votes: 37.5<br />state: New York","hate_groups_per_million: 3.06<br />percent_Trump_votes: 50.5<br />state: North Carolina","hate_groups_per_million: 1.32<br />percent_Trump_votes: 64.1<br />state: North Dakota","hate_groups_per_million: 3.01<br />percent_Trump_votes: 52.1<br />state: Ohio","hate_groups_per_million: 1.53<br />percent_Trump_votes: 65.3<br />state: Oklahoma","hate_groups_per_million: 2.69<br />percent_Trump_votes: 41.1<br />state: Oregon","hate_groups_per_million: 3.13<br />percent_Trump_votes: 48.8<br />state: Pennsylvania","hate_groups_per_million: 0.95<br />percent_Trump_votes: 39.8<br />state: Rhode Island","hate_groups_per_million: 2.42<br />percent_Trump_votes: 54.9<br />state: South Carolina","hate_groups_per_million: 8.09<br />percent_Trump_votes: 61.5<br />state: South Dakota","hate_groups_per_million: 5.71<br />percent_Trump_votes: 61.1<br />state: Tennessee","hate_groups_per_million: 1.97<br />percent_Trump_votes: 52.6<br />state: Texas","hate_groups_per_million: 0.98<br />percent_Trump_votes: 45.9<br />state: Utah","hate_groups_per_million: 1.60<br />percent_Trump_votes: 32.6<br />state: Vermont","hate_groups_per_million: 4.64<br />percent_Trump_votes: 45.0<br />state: Virginia","hate_groups_per_million: 2.88<br />percent_Trump_votes: 38.2<br />state: Washington","hate_groups_per_million: 2.18<br />percent_Trump_votes: 68.7<br />state: West Virginia","hate_groups_per_million: 1.56<br />percent_Trump_votes: 47.9<br />state: Wisconsin","hate_groups_per_million: 3.42<br />percent_Trump_votes: 70.1<br />state: Wyoming"],"type":"scatter","mode":"markers","marker":{"autocolorscale":false,"color":"rgba(0,0,0,1)","opacity":1,"size":5.66929133858268,"symbol":"circle","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)"}},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null},{"x":[-0.4795,10.0695],"y":[41.7937724109846,66.0607962859094],"text":"","type":"scatter","mode":"lines","line":{"width":1.88976377952756,"color":"rgba(0,0,0,1)","dash":"solid"},"hoveron":"points","showlegend":false,"xaxis":"x","yaxis":"y","hoverinfo":"text","frame":null}],"layout":{"margin":{"t":26.2283105022831,"r":7.30593607305936,"b":40.1826484018265,"l":37.2602739726027},"plot_bgcolor":"rgba(235,235,235,1)","paper_bgcolor":"rgba(255,255,255,1)","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187},"xaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[-0.4795,10.0695],"tickmode":"array","ticktext":["0.0","2.5","5.0","7.5","10.0"],"tickvals":[0,2.5,5,7.5,10],"categoryorder":"array","categoryarray":["0.0","2.5","5.0","7.5","10.0"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"y","title":{"text":"Hate groups per million citizens","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"yaxis":{"domain":[0,1],"automargin":true,"type":"linear","autorange":false,"range":[27.995,72.105],"tickmode":"array","ticktext":["30","40","50","60","70"],"tickvals":[30,40,50,60,70],"categoryorder":"array","categoryarray":["30","40","50","60","70"],"nticks":null,"ticks":"outside","tickcolor":"rgba(51,51,51,1)","ticklen":3.65296803652968,"tickwidth":0.66417600664176,"showticklabels":true,"tickfont":{"color":"rgba(77,77,77,1)","family":"","size":11.689497716895},"tickangle":-0,"showline":false,"linecolor":null,"linewidth":0,"showgrid":true,"gridcolor":"rgba(255,255,255,1)","gridwidth":0.66417600664176,"zeroline":false,"anchor":"x","title":{"text":"% votes fpr Trump","font":{"color":"rgba(0,0,0,1)","family":"","size":14.6118721461187}},"hoverformat":".2f"},"shapes":[{"type":"rect","fillcolor":null,"line":{"color":null,"width":0,"linetype":[]},"yref":"paper","xref":"paper","x0":0,"x1":1,"y0":0,"y1":1}],"showlegend":false,"legend":{"bgcolor":"rgba(255,255,255,1)","bordercolor":"transparent","borderwidth":1.88976377952756,"font":{"color":"rgba(0,0,0,1)","family":"","size":11.689497716895}},"hovermode":"closest","barmode":"relative"},"config":{"doubleClick":"reset","showSendToCloud":false},"source":"A","attrs":{"2e825638cc6a":{"x":{},"y":{},"name":{},"type":"scatter"},"2e8230d852bf":{"intercept":{},"slope":{}}},"cur_data":"2e825638cc6a","visdat":{"2e825638cc6a":["function (y) ","x"],"2e8230d852bf":["function (y) ","x"]},"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.2,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
<p class="caption">
Figure 4.5: Percentage of votes for Trump in the 2016 elections for 50 US states and the number of hate groups per 1 million citizens with the estimated regression line.
</p>
</div>
</div>
<div id="hypothesis-testing" class="section level2">
<h2><span class="header-section-number">4.4</span> Hypothesis testing</h2>
<p>As before, there are two main ways in which too look at testing whether the parameters of the simple regression model are different from a priori values. The first is to consider how variable the parameter estimates are under the assumption that the true parameter is identical to the a priori value. The second way is to compare two models, one in which the parameter is fixed to the a priori value, and one where it is freely estimated. Both of these ways will provide us with the same outcome. Personally, I find the model comparison way easier to think about.</p>
<div id="sampling-distribution-of-estimates" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Sampling distribution of estimates</h3>
<p>Remember, an estimate (whether of the mean or of another parameter) is a noisy reflection of the true value of the parameter, and the noise comes from having access only to limited data and not all the data that the data generating process can produce. Suppose in reality there is no relation between hate groups and Trump votes, so that the true slope is <span class="math inline">\(\beta_1 = 0\)</span>. In that case, the model becomes
<span class="math display">\[\begin{align}
Y_i &amp;= \beta_0 + 0 \times X_i + \epsilon \\
&amp;= \beta_0 + \epsilon_i
\end{align}\]</span>
which is identical to the simple model of the previous chapter. Then, the true value of the intercept would be <span class="math inline">\(\beta_0 = \mu\)</span>. If we’d know the true value of the standard deviation <span class="math inline">\(\sigma\)</span>, we’d have a fully specified model (a Normal distribution) which we can use to generate as many alternative data sets as we’d like. By generating these data sets, and estimating the slope of our model for each, we can get an overview of the variability of the estimates when the true slope equals <span class="math inline">\(\beta_1 = 0\)</span>. An unbiased estimator ensures that on average, these estimates equal the true value. The main thing of interest is then the variability around this value. A consistent estimator ensures that this variability becomes smaller with the larger data sets. But to understand how well we can estimate the parameter for the present data, we would simulate data sets with the same number of observations (so <span class="math inline">\(n=50\)</span>). Unfortunately, we don’t know the true value of <span class="math inline">\(\sigma\)</span>. Our data provides an estimate of <span class="math inline">\(\sigma\)</span>, but we know this estimate is noisy itself. Thinking first in the same way about the sampling distribution of <span class="math inline">\(\hat{\sigma}\)</span>, we could first sample a values of <span class="math inline">\(\sigma\)</span>, and then use each of these to generate a data set for which to estimate <span class="math inline">\(\beta_1\)</span>. Doing this many (many many!) times would give us a good overview of the variability of the estimates. As before, we don’t have to actually simulate the data sets. If the null model is true, then we can derive that the sampling distribution of the estimates follows a t-distribution. Thus, we should look for the <span class="math inline">\(t\)</span> value our data provides, and evaluate this value within the context of the sampling distribution derived under the model where <span class="math inline">\(\beta_1 = 0\)</span>. For both paraneters (intercept and slope), the same logic applies. In general then, for parameters <span class="math inline">\(\beta_j\)</span> (where <span class="math inline">\(j = 0\)</span> or 1), the <span class="math inline">\(t\)</span>-value of our data is computed as
<span class="math display">\[\begin{equation}
t_{n-2} = \frac{\hat{\beta}_j}{\text{SE}(\hat{\beta}_j)} \quad \quad \quad t_{n-1} \sim \mathbf{T}(n-2)
\end{equation}\]</span>
where <span class="math inline">\(\text{SE}(\hat{\beta}_j)\)</span> is the standard error of the estimate, which you should remember is the standard deviation of the sampling distribution of the estimates. I won’t bore you with how to compute this standard error; statistical software does a good job at this. One thing to realise though is that the computation assumes that the data always have the same values for the predictor.</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Estimate</th>
<th align="right">Std. Error</th>
<th align="right">t value</th>
<th align="right">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">42.9</td>
<td align="right">2.409</td>
<td align="right">17.80</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">hate_groups_per_million</td>
<td align="right">2.3</td>
<td align="right">0.672</td>
<td align="right">3.43</td>
<td align="right">0.001</td>
</tr>
</tbody>
</table>
</div>
<div id="model-comparison" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Model comparison</h3>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Df</th>
<th align="right">Sum Sq</th>
<th align="right">Mean Sq</th>
<th align="right">F value</th>
<th align="right">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">hate_groups_per_million</td>
<td align="right">1</td>
<td align="right">981</td>
<td align="right">980.8</td>
<td align="right">11.7</td>
<td align="right">0.001</td>
</tr>
<tr class="even">
<td align="left">Residuals</td>
<td align="right">48</td>
<td align="right">4011</td>
<td align="right">83.6</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="confidence-intervals" class="section level2">
<h2><span class="header-section-number">4.5</span> Confidence intervals</h2>
<p>The formula to compute confidence intervals for the two parameters can be written as:
<span class="math display">\[\hat{\beta}_j \pm t_{1-\alpha/2,n-2} \times \text{SE}(\hat{\beta}_j)\]</span>
where <span class="math inline">\(t_{1-\alpha/2,n-2}\)</span> is the right-critical value in a t-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom and a significance level of <span class="math inline">\(\alpha\)</span>. Using <span class="math inline">\(\alpha=.05\)</span> gives us the conventional 95%-confidence interval.</p>
</div>
<div id="assumptions-and-outliers" class="section level2">
<h2><span class="header-section-number">4.6</span> Assumptions and outliers</h2>
<div class="figure" style="text-align: center"><span id="fig:simple-regression-trump2016-residuals-plots"></span>
<img src="_main_files/figure-html/simple-regression-trump2016-residuals-plots-1.svg" alt="Predicted vs residual plot and a QQ plot of the residuals" width="50%" /><img src="_main_files/figure-html/simple-regression-trump2016-residuals-plots-2.svg" alt="Predicted vs residual plot and a QQ plot of the residuals" width="50%" />
<p class="caption">
Figure 4.6: Predicted vs residual plot and a QQ plot of the residuals
</p>
</div>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">4.7</span> Summary</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="a-model-with-a-mean-one-sample-t-test.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 3
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"source": null,
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
