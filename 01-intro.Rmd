# Introduction {#intro}

```{r setup2, echo=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      fig.align = "center")
library(sdamr)
```

In this chapter we will introduce some fundamental concepts, such as experiments, data, analysis, and modelling. We will also introduce you to Paul the octopus.

## Paul the octopus

> We know that all octopus have nine brains so we know he has exceptional powers.  
> _Oliver Walenciak_, Paul's keeper
> irish source: https://www.irishcentral.com/sports/paul-the-psychic-octopus-picks-all-the-world-cup-winners-98010019-238038511)

Paul the Octopus (26 January 2008 â€“ 26 October 2010) was born in the Sea Life Centre in Weymouth, England, and subsequently moved to the aquarium chain's centre in Oberhausen, Germany. It was there he found world-wide fame as a caphalopod oracle. 

```{r, fig.cap="Paul the octpopus predicts Spain to win the final of the 2010 FIFA World Cup"}
knitr::include_graphics("https://static.guim.co.uk/sys-images/Guardian/Pix/pictures/2010/7/15/1279193684789/Paul-the-octopus-005.jpg")
```

Paul began his career during the 2008 UEFA Euro football tournament. In the lead-up to Germany's international football matches, Paul was presented with two clear plastic boxes, each containing food (a mussel or an oyster). Each container was marked with the flag of a team, one the flag of Germany, and the other the flag of Germany's opponent. The box which Paul opened first (and ate its contents) was deemed to be the predicted winner of the match. Paul predicted Germany to win all of their games, a correct prediction in 4 out of 6 cases. He failed to predict their defeats by Croatia in the group stage, and by Spain in the championship's final.

```{r uefa2008, echo=FALSE}
data(uefa2008)
knitr::kable(uefa2008,caption = "Paul's predictions for the UEFA Euro 2008",label = "uefa2008")
```

Two years later, during the 2010 FIFA World football tournament, Paul obtained celebrity status and his divinations were broadcast live on German TV. This time, Paul made correct predictions for all matches in which Germany played, as well as the final between Spain and the Netherlands. 

```{r fifa2010, echo=FALSE}
data(fifa2010)
knitr::kable(fifa2010,caption = "Paul's predictions for the FIFA World Cup 2010")
```

Paul's record of 8/8 correct predictions in the 2010 world cup is quite amazing. The common octopus (_Octopus vulgaris_) is indeed quite an intelligent species. But was Paul really psychic? Could he foresee the future?

## Experiments and observations

We can view Paul's divinations as the result of an experiment to test his psychic abilities. Paul's predictions were derived under more or less controlled conditions: The keeper didn't put Paul's favourite food in the box representing the team he'd hope to win, and didn't always place the box representing Germany on one side of the tank. Had he done one of these things, he might have biased the results. 

A paradigmatic example of an experiment is a randomized-control trial, as common in studies assessing the effectiveness of medication or other therapeutic interventions. In such experiments, a sample of participants is taken from a population of interest, and each participant is randomly assigned to either an experimental condition or control condition. For example, participants in the experimental condition might be given an experimental drug, while participants in the control condition receive a placebo. Ideally, this is done in a "double-blind" setting, where neither the participant nor the person delivering the treatment or otherwise interacting with the participant knows which condition the participant is assigned to. Randomization is key here: By letting chance determine who gets which treatment, characteristics of the participants (e.g. age, sex, severity of symptoms, __etc__) will not be tied to the treatment they get. As such, it will be reasonable to assume that the experimental and control condition differ only in their treatment, such that any differences in outcome can be attributed to the treatment, and not to other differences between the groups of participants. 

Causality

Data obtained under less stringent conditions is often referred to as observational data. For instance, rather than random assignment, we could let the doctor choose which treatment to give to which patient. The doctor might choose to give the experimental drug to the more severe cases, and the placebo to the less severe cases. Severity is now __confounded__ with the treatment, and any difference in outcome success observed between the experimental and control condition might be due to the treatment, or to the initial differences in severity. Or even to a third variable such as age, which is itself related to severity. In this case, we wouldn't be able to tell, and hence the conclusions we can draw about the effects of the treatment and much less straightforward. We are not completely helpless though. Using statistics, we can attempt to control for pre-existing differences. As we will see in due course, we can attempt to build a model which includes both treatment and disease severity as predictors of outcome. In doing so, we can attempt to estimate the unique effect of treatment on outcome. By considering only those differences in outcome that cannot be attributed to severity, we can still say something meaningful about treatment effects.  

## Data

__Data__ are a collection of measured or otherwise observed or known values of __variables__. A variable is 
In a statistical model, a __dependent variable__ is a variable of interest, a variable which we aim to predict, explain, or describe. An __independent variable__ is a variable which we use to help predict, explain, or describe the dependent variable. For instance, in the medical example above, the dependent variable would be the severity of symptoms, while independent variables would be the treatment (medication or placebo), and potentially other factors such as patients' age, sex, etc. Whether a variable is a dependent or independent variable may differ from model to model. As such, it is an aspect of the analysis, and not so much of the design of a study. 

Paul has provided us with two sets of data. The first contains his predictions for the 2008 UEFA Cup, and the second his predictions for the 2010 FIFA Cup. The dependent variable in both sets is the accuracy of Paul's predictions. Paul's "predictions" were of course not directly predictions who was going to win each game. Paul made a choice which of two containers to open first. But we're not really interested in whether Paul opened the left or right container in his tank, or whether Paul chose the container with the Spanish flag or the container with the Dutch flag. What we are interested in is whether the first container to be opened contained the flag of the team that would win the match played that day. If it did, Paul made a correct prediction, if not, Paul made an incorrect prediction. The data then contains information about what we deem relevant to our purposes. In a sense, looking just at the accuracy of Paul's predictions, we have already abstracted quite a bit from the experiment. We ignore whether Paul went left or right first, how long it took him to open the first container, ... These are all aspects of Paul's behaviour which we could have focused on, and hence could be variables in our data. These variables have different characteristics. For instance, accuracy (correct or incorrect) and direction (left or right container) both have only two possible values, while the duration until opening the first container has many possible values. Variables with a finite (limited) number of values are called discrete, while variables with an infinite (unlimited) number of values are called continuous.  

### Measurement scales

* A __nominal scale__ allows identifying values as "identical" or "different", but nothing more. Examples of variables on a nominal scale are pizza toppings, eye colour, etc. While we can assign numbers to the values (e.g. brown = 1, blue = 2, green = 3), these are arbitrary and can be changed without much consequence (e.g. brown = 21, blue = 7, green = 1). 
* An __ordinal scale__ allows values to be identified as "smaller", "identical", or "larger", but nothing more. Variables on an ordinal scale can be meaningfully ordered or ranked. This means there is some constraint to numbers we can assign to values. 
* An __interval scale__ allows items to be assigned more meaningful numbers. On an interval scale, the differences between numbers can themselves be meaningfully ordered. Temperature is a common example. The difference between 16 and 14 degrees Celcius is smaller than the difference between 19 and 16 degrees Celcius. But we can not say that 30 degrees Celcius is twice as warm as 15 degrees Celcius. This is because an interval scale doesn't have a fixed 0 point. For degrees Celcius, 0 degrees is the point at which water freezes. It is not the point at which there is no temperature. 
* A __ratio scale__ has everything an interval scale has, with the addition of an absolute 0 point. Weight is a common example. Not only can we say that the difference between 3 and 2 kilograms is smaller than the difference between 10 and 5 kilograms, we can also say that 10 kilograms is twice as heavy as 5 kilograms, and that an item with a weight of 0 kilograms has no weight whatsoever.

Sometimes it is tricky to determine what the measurement scale is. For instance, are "correct" and "incorrect" ordered (correct is better than incorrect) or nominal? Most of the time, a courser distinction is enough, namely whether data is __categorical__ (nominal or ordinal) or __metric__ (interval or ratio).

### The Data Generating Process

In addition to considering the type or measurement scale of the data, you will generally also need to consider the process that led to the data. As the section on experimental vs observational data indicated, the way the data were obtained can affect and limit the inferences that can be made. It is also important to consider the 

The __Data Generating Process__ (or DGP for short) is a concept we will use repeatedly throughout this book, so it's worth spending a little time on what it means. 

## Exploring and describing data

Once you have collected data, you may feel the urge to immediately apply some statistical test to it. But really, a first step should be to explore the data. Statistical tests are designed to confirm or reject hypotheses, and part of __confirmatory data analysis__. They are a very important part of scientific research, but they always rely on assumptions about the data generating process. Before conducting these analyses, it is crucial to assess whether these assumptions are reasonable, and this is where __exploratory data analysis__ can help. @Tukey1977EDA, a major proponent of exploratory data analysis, also points out that exploratory data analysis can also suggest new hypotheses about the causes of observed phenomena, and with that provide a basis for further experimentation and data collection.

### Summary statistics

#### Measures of location

* Mean
* Median
* Mode

#### Measures of spread

* Inter-quartile range
* Variance
* Standard deviation

### Visual exploration

Exploring a data set is generally done visually, using various plots such as boxplots, histograms, scatterplots, etc. It is also useful to obtain some summary statistics.  such as averages, and measures of the spread of values, show minimum and maximum val

## Analysis and modeling

Analysing data can mean lots of things. One view I quite like is that data analysis is identifying a signal within noise. 

Statistical modeling can be viewed as describing the __Data Generating Process__. 

## Summary